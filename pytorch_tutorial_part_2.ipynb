{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17212bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bfc155",
   "metadata": {},
   "source": [
    "# Fully Connected Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315624dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = torch.nn.Linear(5, 10)  # input feature dim = 5, output feature dim = 10\n",
    "input_t = torch.rand(1, 5)  # batch size = 2, feature dim = 5\n",
    "\n",
    "output_t = linear(input_t)\n",
    "\n",
    "optim = torch.optim.SGD(linear.parameters(), lr=1e-2)\n",
    "# optim = torch.optim.SGD([linear.weight, linear.bias], lr=1e-2)\n",
    "for n, val in linear.named_parameters():\n",
    "    print(n, val)\n",
    "\n",
    "s = torch.sum(output_t)\n",
    "optim.zero_grad()\n",
    "s.backward()\n",
    "\n",
    "# print(\"\\nOutput:\")\n",
    "# print(output_t.shape, \"\\n\")\n",
    "# print(\"Parameters:\")\n",
    "# print(\"Weight:\", linear.weight.shape)\n",
    "# print(\"Bias:\", linear.bias.shape, \"\\n\")\n",
    "\n",
    "print(\"\\nWeight Gradient:\", linear.weight.grad)\n",
    "print(\"Bias   Gradient:\", linear.bias.grad)\n",
    "optim.step()\n",
    "print(\"\\nAfter Gradient Update:\")\n",
    "print(\"Weigths: \", linear.weight)\n",
    "print(\"Bias: \", linear.bias)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac52481",
   "metadata": {},
   "source": [
    "# Convolutional Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061e914c",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = torch.nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=0)\n",
    "# Input: Batch x channel x height x width\n",
    "input_t = torch.rand(10, 3, 32, 32)\n",
    "output_t = conv(input_t)\n",
    "\n",
    "# ========================#\n",
    "# Output Shape:          #\n",
    "# (W - K + 2P)/S + 1     #\n",
    "# (32 - 3 + 0)/1 + 1 = 30#\n",
    "# ========================#\n",
    "\n",
    "print(\"Output:\")\n",
    "print(output_t.shape)\n",
    "print(\"Parameters:\")\n",
    "print(\"Weights:\", conv.weight.shape)\n",
    "print(\"Bias:\", conv.bias.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10ff8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = torch.nn.Conv2d(3, 32, 3, stride=1, padding=1)\n",
    "input_t = torch.rand(10, 3, 32, 32)\n",
    "output_t = conv(input_t)\n",
    "\n",
    "# ========================#\n",
    "# Output Shape:          #\n",
    "# (W - K + 2P)/S + 1     #\n",
    "# (32 - 3 + 2)/1 + 1 = 32#\n",
    "# ========================#\n",
    "\n",
    "print(\"Output:\")\n",
    "print(output_t.shape)\n",
    "print(\"Parameters:\")\n",
    "print(\"Weights:\", conv.weight.shape)\n",
    "print(\"Bias:\", conv.bias.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c543c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = torch.nn.Conv2d(3, 16, 3, stride=2)\n",
    "input_t = torch.rand(10, 3, 32, 32)\n",
    "output_t = conv(input_t)\n",
    "\n",
    "# ===============================#\n",
    "# Output Shape:                 #\n",
    "# (W - K + 2P)/S + 1            #\n",
    "# (32 - 3 + 0)/2 + 1 = 15.5 = 15#\n",
    "# When the answer is not a whole#\n",
    "# number we take the greatest   #\n",
    "# integer of the output.        #\n",
    "# ===============================#\n",
    "\n",
    "print(\"Output:\")\n",
    "print(output_t.shape)\n",
    "print(\"Parameters:\")\n",
    "print(\"Weights:\", conv.weight.shape)\n",
    "print(\"Bias:\", conv.bias.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166a125b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================#\n",
    "# Transposed Convolutions,       #\n",
    "# Deconvolutions,                #\n",
    "# Upconvolutions                 #\n",
    "# (W - 1) * S - 2P + (K-1) + 1   #\n",
    "# (30-1) * 1 - 0 + (3-1) + 1 = 32#\n",
    "# ================================#\n",
    "tconv = torch.nn.ConvTranspose2d(in_channels=32, out_channels=3, kernel_size=3, stride=1, padding=0)\n",
    "input_t = torch.rand(10, 32, 30, 30)\n",
    "output_t = tconv(input_t)\n",
    "\n",
    "print(\"Output:\")\n",
    "print(output_t.shape)\n",
    "print(\"Parameters:\")\n",
    "print(\"Weights:\", tconv.weight.shape)\n",
    "print(\"Bias:\", tconv.bias.shape)\n",
    "\n",
    "conv = torch.nn.Conv2d(3, 32, 3, 1, 0)\n",
    "input_again = conv(output_t)\n",
    "\n",
    "print(\"\\nInput Again:\")\n",
    "print(input_again.shape)\n",
    "print(\"Parameters:\")\n",
    "print(\"Weights:\", conv.weight.shape)\n",
    "print(\"Bias:\", conv.bias.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f8d16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = torch.nn.Conv2d(3, 32, 3, stride=1, padding=1)\n",
    "input_t = torch.rand(\n",
    "    10,\n",
    "    3,\n",
    "    32,\n",
    "    32,\n",
    ")\n",
    "output_t = conv(input_t)\n",
    "\n",
    "s = torch.norm(output_t, p=2)\n",
    "s.backward()\n",
    "\n",
    "print(\"Output:\")\n",
    "print(output_t.shape)\n",
    "print(\"Parameters:\")\n",
    "print(\"Weights:\", conv.weight.shape)\n",
    "print(\"Bias:\", conv.bias.shape)\n",
    "\n",
    "print(\"Weight gradient:\", conv.weight.grad.shape)\n",
    "print(\"Bias gradient: \", conv.bias.grad.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0deca5",
   "metadata": {},
   "source": [
    "# Building Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8d75eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "model = nn.Sequential(nn.Conv2d(1, 20, 5), nn.ReLU(), nn.Conv2d(20, 64, 5), nn.ReLU())\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06405343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of using Sequential with OrderedDict\n",
    "from collections import OrderedDict\n",
    "\n",
    "model = nn.Sequential(\n",
    "    OrderedDict(\n",
    "        [(\"conv1\", nn.Conv2d(1, 20, 5)), (\"relu1\", nn.ReLU()), (\"conv2\", nn.Conv2d(20, 64, 5)), (\"relu2\", nn.ReLU())]\n",
    "    )\n",
    ")\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d2912b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        # Define Convolutional Layers\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        # Dropout\n",
    "        self.dropout1 = nn.Dropout(p=0.25)\n",
    "        self.dropout2 = nn.Dropout(p=0.5)\n",
    "        # Define fully connected layers\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = x\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "model_test = MyModel()\n",
    "model_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18bbd14",
   "metadata": {},
   "source": [
    "# Choosing Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d690e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.rand(2, 4, 5)\n",
    "print(tensor.device)\n",
    "# We move our tensor to the GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "# Copy your tensors to the GPU\n",
    "tensor = tensor.to(device)\n",
    "print(tensor.device)\n",
    "\n",
    "# Run operations on Multiple GPUs parallely\n",
    "tensor = torch.nn.DataParallel(tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bab0d9",
   "metadata": {},
   "source": [
    "# Create Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaf0db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class RandomDataset(Dataset):\n",
    "    def __init__(self, dim, length):\n",
    "        self.len = length\n",
    "        self.data = torch.randn(length, dim)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return torch.tensor(self.data[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "\n",
    "rand_loader = DataLoader(dataset=RandomDataset(5, 100), batch_size=30, shuffle=True, num_workers=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154c562f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in rand_loader:\n",
    "    x_batch = data\n",
    "    print(data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a5438e",
   "metadata": {},
   "source": [
    "# A Simple Training Workflow using Pytorch (MNIST Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5217fb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Specify the device to use.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using \", device)\n",
    "# ===============================================#\n",
    "# Get Data                                      #\n",
    "# MNIST is available inside PyTorch and we      #\n",
    "# do not have to write our own custom dataloader#\n",
    "# ===============================================#\n",
    "\n",
    "# IMPORTANT to transform image data to tensor!\n",
    "# This step converts pixel values between 0-255\n",
    "# to floats between 0-1.\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        #         transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_dataset = datasets.MNIST(\"data\", train=True, download=True, transform=transform)\n",
    "\n",
    "# print(len(train_dataset))\n",
    "# example_x, example_y = train_dataset[20]\n",
    "# print(example_x.min(), example_x.max())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "# Create Model and send to device\n",
    "model = MyModel().to(device)\n",
    "# Define your optimizer. Here we are using Adam with default parameters.\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "# print(optimizer.param_groups[0].keys())\n",
    "# Set the model to train\n",
    "model.eval()\n",
    "# print(model.training)\n",
    "\n",
    "epoch_loss = []\n",
    "start_time = time.time()\n",
    "print(\"\\nTRAINING...\")\n",
    "for epoch in range(1, 11):\n",
    "    print(\"\\nEpoch: \", epoch)\n",
    "    running_loss = 0\n",
    "    e_time = time.time()\n",
    "    # Iterate over the entire dataset\n",
    "    for b_id, (x, y) in enumerate(train_loader, 1):\n",
    "        # IMPORTANT to send data to device.\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        # Remove old gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(x)\n",
    "        train_loss = F.cross_entropy(output, y)  # Using cross entropy loss for classification.\n",
    "\n",
    "        # Backpropagation\n",
    "        train_loss.backward()\n",
    "        # Gradient Update\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += (train_loss - running_loss) / b_id\n",
    "    print(\n",
    "        \"Average Epoch Loss: {:.4f}\".format(running_loss.item()),\n",
    "        \"Time Taken: {:.2f}s\".format(time.time() - e_time, \"\\n\"),\n",
    "    )\n",
    "    epoch_loss.append(running_loss.cpu().detach().numpy())\n",
    "\n",
    "print(\"Training Time: {:.2f}s\".format(time.time() - start_time))\n",
    "plt.plot(range(0, 10), epoch_loss)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Training Loss\")\n",
    "plt.title(\"MNIST Classification\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f960a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img * 255.0  # unnormalize\n",
    "    npimg = img.numpy().astype(np.uint8)\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "imshow(torchvision.utils.make_grid(images[:6]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
